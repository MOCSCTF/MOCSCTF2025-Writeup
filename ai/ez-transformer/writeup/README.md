## flag

MOCSCTF{eeezzzz_transf0rmer_cha11eng3}

## 解題步驟

server.py是伺服器部署的來源碼。可以看到使用了TinyStories-33M這個模型。選手需要去了解這個模型的特色。

它是基於transformer架構，是一個decoder-only類型的模型。即它的主要功能是基於輸入的提示詞進行句子的預測，但是由於它是一個很簡單的模型並且沒有通過對齊訓練，它的輸出不一定就是和輸入強相關的。

我們需要了解模型是如何產生文字的：

**自迴歸產生模型** 會逐步預測下一個 token（字或子詞）：

1. 你輸入一個開始的文字（例如："Once upon a time"）。
2. 模型預測下一個最可能的 token（基於輸入的機率分佈），然後將該 token 加入輸入中，作為下一個步驟的輸入。
3. 重複此過程，直到產生滿足要求的文字。

如果沒有引入 **隨機性**，且輸入和模型設定保持不變（例如，溫度、採樣策略），每次模型都會選擇相同的 **最可能的下一個 token**。

對於如 TinyStories-33M，在生成時，通常會預設使用較低溫度和貪心策略（或類似的確定性策略），所以輸入相同時輸出是確定的。

那我們可以直接去根據TinyStories-33M的詞表進行暴力遍歷（因為詞表也不大），看看什麼樣的輸入會產生success這個輸出，並且篩選出長度等於10的即可。

一些可能的結果：

```

  1%|          | 18/1571 [00:21<30:46,  1.19s/it]spe
  2%|▏         | 30/1571 [00:35<30:36,  1.19s/it]Ġtraders
  4%|▍         | 61/1571 [01:13<31:44,  1.26s/it]Ġcomplied
  4%|▍         | 65/1571 [01:18<31:00,  1.24s/it]ĠNeither
  5%|▍         | 71/1571 [01:25<31:15,  1.25s/it]Ġdeceived
  6%|▌         | 98/1571 [01:59<31:24,  1.28s/it]Ġextending
```

Ġextending就可以。

